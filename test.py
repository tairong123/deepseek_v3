from langchain.document_loaders import PyPDFLoader, UnstructuredWordDocumentLoader 
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.llms import Ollama
import glob

# æ•™ç§‘æ›¸ PDF
textbook_docs = PyPDFLoader("docs/mydoc.pdf").load()

# å°±è¨ºå»ºè­° PDFï¼ˆLung-RADSï¼‰
lung_rads_docs = PyPDFLoader("docs/lung-rads-assessment-categories.pdf").load()

# è‡¨åºŠè§€å¯Ÿè³‡æ–™ï¼ˆ.docx Wordï¼‰
clinical_docs = [UnstructuredWordDocumentLoader(path).load() for path in glob.glob("data/*.docx")]

# 2. åˆ†æ®µè™•ç†
all_docs = sum([textbook_docs, lung_rads_docs] + clinical_docs, [])
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = splitter.split_documents(all_docs)

# 3. å»ºç«‹å‘é‡è³‡æ–™åº«
embedding_model = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
db = FAISS.from_documents(split_docs, embedding_model)

# 4. å°è©±è¨˜æ†¶
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    output_key="answer"
)

llm = Ollama(model="deepseek-r1:7b")

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=db.as_retriever(search_kwargs={"k": 4}),
    memory=memory,
    return_source_documents=True,
    output_key="answer"
)
# 7. å•ç­”ä»‹é¢
def chat():
    print("ğŸ“„ è«‹è¼¸å…¥æ¨¡æ“¬è§€å¯Ÿå…§å®¹ï¼ˆå¦‚ï¼šRUL æœ‰ 45mm çµç¯€...ï¼‰ï¼Œè¼¸å…¥ q é›¢é–‹")

    while True:
        obs = input("ä½ ï¼š")
        if obs.lower() == "q":
            break

        prompt = f"""
è«‹ä½ æ‰®æ¼”ä¸€ä½æ”¾å°„ç§‘é†«å¸«ï¼Œæ ¹æ“šä½ å­¸ç¿’çš„è³‡æ–™ï¼ˆåŒ…å« mydoc.pdf çš„æ•™æå…§å®¹ï¼‰èˆ‡ Lung-RADS è©•ä¼°æŒ‡å¼•ï¼Œæ ¹æ“šä»¥ä¸‹è§€å¯Ÿå…§å®¹æ’°å¯«è¨ºæ–·å ±å‘Šä¸¦ä»¥æ‚£è€…çš„è§’åº¦çµ¦äºˆæ˜“æ‡‚çš„å»ºè­°ã€‚

è«‹ä¾ç…§ä»¥ä¸‹æ ¼å¼ç”¢å‡ºï¼š

---
ã€è‚ºéƒ¨æ‰€è¦‹ã€‘ï¼šï¼ˆæ¢åˆ—è‚ºéƒ¨ç•°å¸¸ï¼‰
ã€å¿ƒè¡€ç®¡ã€‘ï¼šï¼ˆæ¢åˆ—å¿ƒè¡€ç®¡ç•°å¸¸ï¼‰
ã€ç¸±éš”ã€‘ï¼šï¼ˆæ¢åˆ—ç¸±éš”æˆ–æ·‹å·´çµç•°å¸¸ï¼‰
ã€Lung RADS åˆ†é¡ã€‘ï¼š(æ ¹æ“šçµ¦äºˆçš„ç‰¹å¾µæ¢åˆ—åˆ†é¡å…§å®¹)
ã€ç¸½çµå°è±¡ã€‘ï¼šï¼ˆæ ¹æ“šè§€å¯Ÿç¸½çµç—…ç¶æ€§è³ªèˆ‡å»ºè­°ï¼Œå¯åƒè€ƒ lung-rads-assessment-categories.pdfï¼Œä¸¦å¯«å‡ºLung
RADSï¼Œfindingï¼Œmanagementï¼‰
---

ä»¥ä¸‹ç‚ºè§€å¯Ÿå…§å®¹æè¿°ï¼š
"{obs}"
"""

        result = qa_chain.invoke({"question": prompt})
        print("\nğŸ“‹ AI å ±å‘Šï¼š\n")
        print(result["answer"])
        print("\n---\n")

chat()